{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "akwam-dl_forColab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1lIpge/Oohx3af8B7smhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EyadNasr/akwam-dl/blob/main/akwam_dl_forColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "OYQZzgpUmzyl",
        "outputId": "2cc6ba39-94a6-443f-b6fa-e0e9f308bf38"
      },
      "source": [
        "\n",
        "#@markdown <br><center><img src='https://raw.githubusercontent.com/EyadNasr/akwam-dl/main/akwam_logo.ico' height=\"50\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h3>Akwam Links Generator</h3></center><br>\n",
        "\n",
        "import os\n",
        "if not os.path.isdir('/content/akwam-dl'):\n",
        "  !git clone https://github.com/EyadNasr/akwam-dl\n",
        "  os.chdir('/content/akwam-dl')\n",
        "\n",
        "\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from sys import stdout, stdin\n",
        "from re import match, findall, DOTALL\n",
        "from requests import get\n",
        "from numpy import unique\n",
        "from os import mkdir,chdir, getcwd, system\n",
        "from os.path import isfile, isdir\n",
        "from time import sleep\n",
        "from Arabic_Reshaper import reshape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def connproblem():\n",
        "    print(\"\\n\\nTHERE IS A PROBLEM WITH YOUR CONNECTION, CHECK YOUR INTERNET CONNENCTION AND TRY AGAIN!\")\n",
        "    ask = input('\\nTry again [y] or quit [n]? Press [y] to retry or [n] to quit')\n",
        "    if ask == 'y' or ask == 'Y': \n",
        "        print('')\n",
        "        pass\n",
        "    else: raise SystemExit\n",
        "\n",
        "\n",
        "def retrynow(num):\n",
        "    ssss = 'CONNECTION ERROR... Retrying... (' + str(num) + ')'\n",
        "    if num == 1: print('\\n')\n",
        "    stdout.flush()\n",
        "    stdout.write('\\r'+ ssss)\n",
        "    sleep(10)\n",
        "    if num%10 == 0: connproblem()\n",
        "    return num\n",
        "\n",
        "\n",
        "def keyinter():\n",
        "    print(\"\\n\\nPROGRAM INTERRUPT BY USER\\n\")\n",
        "    raise SystemExit\n",
        "\n",
        "\n",
        "def getlinks(url, stwith):\n",
        "    iternum = 1\n",
        "    while True:\n",
        "        try:\n",
        "            hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "            req = Request(url,headers=hdr)\n",
        "            page = urlopen(req).read()\n",
        "            if iternum > 1: print('\\n')\n",
        "            break\n",
        "        except KeyboardInterrupt: keyinter()\n",
        "        except Exception: iternum = retrynow(iternum)\n",
        "        iternum = iternum + 1\n",
        "    soup = BeautifulSoup(page, \"html.parser\")\n",
        "# Retrieve all of the anchor tags\n",
        "    tags = soup('a')\n",
        "    #lst = [tag.get('href', '') for tag in tags if match(stwith, tag.get('href', ''))]\n",
        "    lst = []\n",
        "    epidic = {}\n",
        "    for tag in tags:\n",
        "        if match(stwith, tag.get('href', '')) and tag.get('class') == ['text-white']:\n",
        "            lst = lst + [tag.get('href', '')]\n",
        "            #print(tag.contents)\n",
        "            epidic[int(findall('.+? ([0-9]+)', tag.contents[0])[0])] = tag.get('href', '')\n",
        "    #print(epidic)\n",
        "    #newlst = [item for item in lst if lst.count(item) == 2]\n",
        "    #newlst = newlst[::-2]\n",
        "    return(epidic)\n",
        "\n",
        "\n",
        "def getlistOfSeasons(parent, findit, fff, episodesFlag):\n",
        "    if findit == '\"(https://.*?ak.+?/(movie|series)/.+?)\"':\n",
        "        findit1 = '\"(https://.*?ak.+?/series/.+?)\"'\n",
        "        findit2 = '\"(https://.*?ak.+?/movie/.+?)\"'\n",
        "        finditboth = [findit1, findit2]\n",
        "        parentboth = [parent+'series', parent+'movie']\n",
        "    else:\n",
        "        finditboth = [findit]\n",
        "        parentboth = [parent]\n",
        "    bothdict = {}\n",
        "    extracted_websub = ''\n",
        "    for both1, both2 in zip(parentboth, finditboth):\n",
        "        parent = both1\n",
        "        iternum = 1\n",
        "        while True:\n",
        "            try:\n",
        "                r = get(parent)\n",
        "                x = r.content.decode(\"utf-8\")\n",
        "                findit = both2\n",
        "                r = get(parent)\n",
        "                x = r.content.decode(\"utf-8\")\n",
        "                if iternum > 1: print('\\n')\n",
        "                break\n",
        "            except KeyboardInterrupt: keyinter()\n",
        "            except Exception: iternum = retrynow(iternum)\n",
        "            iternum = iternum + 1\n",
        "        if fff:\n",
        "            morePages = findall('page=([1-9]+)', x)\n",
        "            Pages = unique(morePages).tolist()\n",
        "            Pages = [1] + [int(i) for i in Pages]\n",
        "            Pages = list(range(1, max(Pages)+1))\n",
        "            all_X = ''\n",
        "            for i in Pages:\n",
        "                if i == 1: all_X = all_X + ' ' + x\n",
        "                else:\n",
        "                    parent_i = parent + '&page=' + str(i)\n",
        "                    iternum = 1\n",
        "                    while True:\n",
        "                        try:\n",
        "                            r = get(parent_i)\n",
        "                            x = r.content.decode(\"utf-8\")\n",
        "                            if iternum > 1: print('\\n')\n",
        "                            break\n",
        "                        except KeyboardInterrupt: keyinter()\n",
        "                        except Exception: iternum = retrynow(iternum)\n",
        "                        iternum = iternum + 1\n",
        "                    all_X = all_X + ' ' + x\n",
        "            aka = r'<h3 class=\"entry-title font-size-14 m-0\"><a href=\"(https://.*?ak.+?/(movie|series)/[^\" \\t\\n\\r\\f\\v]+)\".+\\n.+\\n.+\"badge badge-pill badge-secondary ml-1\">([0-9][0-9][0-9][0-9])</span>'\n",
        "            uniq = findall(aka, all_X)\n",
        "            try: \n",
        "                if len(uniq) > 0: \n",
        "                    extracted_websub = findall('(https://.+?)/[^ \\t\\n\\r\\f\\v]+', uniq[0][0])[0]\n",
        "                    #uniq.remove(parent)\n",
        "            except: \n",
        "                pass\n",
        "            unsrt = [int(i[0].split('/')[-2]) for i in uniq]\n",
        "            dicto = {}\n",
        "            \n",
        "            for i in range(0, len(uniq)): dicto[unsrt[i]] = uniq[i][0] + ' ' + uniq[i][2]\n",
        "        else:\n",
        "            uniq = findall(findit, x)\n",
        "            extracted_websub = findall('(https://.*?ak.+?)/[^ \\t\\n\\r\\f\\v]+', uniq[0])[0]\n",
        "            uniq = unique(uniq).tolist()\n",
        "            unsrt = [int(i.split('/')[-2]) for i in uniq]\n",
        "            dicto = {}\n",
        "            for i in range(0, len(uniq)): dicto[unsrt[i]] = uniq[i]\n",
        "        bothdict.update(dicto)\n",
        "    dicto = bothdict\n",
        "    lsts = []\n",
        "    if len(dicto) == 1: sstr = ' Link found'\n",
        "    else: sstr = ' Links found'\n",
        "    print('\\n' + str(len(dicto)) + sstr)\n",
        "    count = 1\n",
        "    for j in sorted(dicto):\n",
        "        #reshaped_text = reshape(dicto[j])\n",
        "        bidi_text = dicto[j]\n",
        "        s = str(dicto[j].encode())\n",
        "        links = []\n",
        "        TYPE = '\" [' + bidi_text.split('/')[-3] + ']'\n",
        "        ending = input('\\n' + str(count) + ' Do you want to download \"' + bidi_text.split('/')[-1].replace('-s-', \"'s \").replace('-', ' ') + TYPE + ' ?')\n",
        "        flag = True\n",
        "        if ending == 'y'  or ending == 'Y':\n",
        "            if bidi_text.find('series') != -1:\n",
        "                if fff: linksdic = getlinks(findall(\"'(.+)'\", s)[0][:-5], extracted_websub + '/episode/')\n",
        "                else: linksdic = getlinks(findall(\"'(.+)'\", s)[0], extracted_websub + '/episode/')\n",
        "                episodessorted = sorted(linksdic)\n",
        "                links = [linksdic[i] for i in episodessorted]\n",
        "                if episodesFlag:\n",
        "                    print('\\n' + '\"' + bidi_text.split('/')[-1].replace('-', ' ') + '\" has', max(episodessorted), 'episodes.')\n",
        "                    episodeslst = input('Enter the desired episodes: ')\n",
        "                    cond = 0\n",
        "                    numset = '0123456789:,'\n",
        "                    while cond == 0:\n",
        "                        episodeslst = episodeslst.replace(' ', '').replace('\\t', '').split(',')\n",
        "                        for e in episodeslst:\n",
        "                            #if all(x in numset for x in episodeslst): pass\n",
        "                            if len(findall('^[1-9]+[0]*$', e)) > 0 and int(e) <= max(episodessorted): pass\n",
        "                            elif len(findall('^[1-9]+[0]*:[1-9]+[0]*$', e)) > 0 and int(e.split(':')[0]) < int(e.split(':')[1]) and int(e.split(':')[1]) <=max(episodessorted): pass\n",
        "                            else:\n",
        "                                episodeslst = input('Invalid input, Enter the desired episodes: ')\n",
        "                                cond = cond + 1\n",
        "                        if cond > 0: cond = 0\n",
        "                        else: break\n",
        "                    \n",
        "                    candlist = []\n",
        "                    for i in episodeslst:\n",
        "                        if ':' not in i: candlist.append(int(i))\n",
        "                        else: candlist = candlist + list(range(int(i.split(':')[0]), int(i.split(':')[1])+1))\n",
        "                    pro = sorted(unique(candlist).tolist())\n",
        "                    links = []\n",
        "                    missing = []\n",
        "                    for i in pro:\n",
        "                        if i not in linksdic: missing = missing + [i]\n",
        "                        else: links = links + [linksdic[i]]\n",
        "                    if len(missing) > 0:\n",
        "                        print('\\nThe following episodes are missing from the website: ', end='')\n",
        "                        for q in missing: print(q, '', end='')\n",
        "                        print('')\n",
        "            elif bidi_text.find('movie') != -1:\n",
        "                if fff: links = [bidi_text[:-5]]\n",
        "                else: links = [bidi_text]\n",
        "        lsts = lsts + links\n",
        "        if ending == 'q':\n",
        "            break\n",
        "        count = count + 1\n",
        "    links = lsts\n",
        "    return links\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    websub = 'https://.*?ak.+?'\n",
        "    flag = False\n",
        "    episodesFlag = False\n",
        "    while True:\n",
        "        allLinks1 = []\n",
        "        sizes = []\n",
        "        quals = []\n",
        "        quals_dict = {'5': '1080', '4': '720', '3': '480', '2': '360', '1': '240'}\n",
        "        quals_dict_rev = {'1080': '5', '720': '4', '480': '3', '360': '2', '240': '1'}\n",
        "        parent = input('Paste Movie or Series link, (or write what you want to search for): ')\n",
        "        name = parent.split('/')[-1].split('%')[0].replace('-', ' ').strip()\n",
        "        if parent.find('https:') == -1:\n",
        "            parent = 'https://akw.to/search?q=' + parent\n",
        "        if parent.find('series') != -1:\n",
        "            fff = False\n",
        "            print(\"\\nPress [q] to end questions, [y] to download or [n] to skip:\")\n",
        "            websub1 = 'https://' + parent[8:].split('/')[0]\n",
        "            links = getlistOfSeasons(parent, '\"(' + websub1 + '/series/.+?)\"', fff, episodesFlag)\n",
        "        elif parent.find('search') != -1:\n",
        "            fff = True\n",
        "            ending = input('\\nIs it a Movie or a Series or both?\\n(Enter [m] for Movie, [s] for Series , [e] for specific Episodes of a series or any other key for both Movies and Series)\\n')\n",
        "            if ending == 'm' or ending == 'M': \n",
        "                Type = '&section=movie'\n",
        "                Typo = '&section=movie'\n",
        "            elif ending == 's' or ending == 'S': \n",
        "                Type = '&section=series'\n",
        "                Typo = '&section=series'\n",
        "            elif ending == 'e' or ending == 'E':\n",
        "                Type = '&section=series'\n",
        "                Typo = '&section=series'\n",
        "                episodesFlag = True\n",
        "            else: \n",
        "                Type = '&section=(movie|series)'\n",
        "                Typo = '&section='\n",
        "            if episodesFlag: print('To specify episodes: type the range of episodes or episode numbers separated by commas\\nfor example: 1,4,7,9:12,15')\n",
        "            else: print('')\n",
        "            print(\"\\nPress [q] to end questions, [y] to download or [n] to skip:\")\n",
        "            links = getlistOfSeasons(parent.replace(' ', '+')+Typo, '\"(' + websub + '/' + Type[9:] + '/.+?)\"', fff, episodesFlag)\n",
        "            name = parent.split('/')[-1].split('%')[0].replace('-', ' ').split('&')[0].split('?q=')[1].replace('+', ' ')\n",
        "            if len(links) == 0 and not flag:\n",
        "                print('\\nDid not find what you were searching for!')\n",
        "        elif parent.find('movie') != -1:\n",
        "            links = [parent]\n",
        "        else: links = []\n",
        "        if len(links) == 0:\n",
        "            print('\\nZero links extracted!')\n",
        "        else:\n",
        "            print('')\n",
        "            for i in links:\n",
        "                sss = \"Gathering download pages... ( \" + str(links.index(i)+1) + \" out of \" + str(len(links)) + \" )\"\n",
        "                stdout.flush()\n",
        "                stdout.write('\\r'+ sss)\n",
        "                iternum = 1\n",
        "                while True:\n",
        "                    try:\n",
        "                        r = get(i)\n",
        "                        z = r.content.decode(\"utf-8\")\n",
        "                        if iternum > 1: print('\\n')\n",
        "                        break\n",
        "                    except KeyboardInterrupt: keyinter()\n",
        "                    except Exception: iternum = retrynow(iternum)\n",
        "                    iternum = iternum + 1\n",
        "                #downlink1 = findall('\"(http://go.akwam' + websuper + '/link/.+?)\".+?([0-9.,]+ [MG]B)', z)\n",
        "                #downlink1 = findall('data-quality=\"([1-5])\">.+?\"(http://re.two.re/link/.+?)\".+?([0-9.,]+ [MG]B)', z, DOTALL)\n",
        "                downlink1 = findall('data-quality=\"([1-5])\">.+?<a href=\"(http://[^\" \\t\\n\\r\\f\\v]+/link/[^\" \\t\\n\\r\\f\\v]+?)\".+?([0-9.,]+ [MG]B)</span>', z, DOTALL)\n",
        "                #downlink1 = findall('\"(' + websub + '/download/.+?)\".+?([0-9.,]+ [MG]B)', z)\n",
        "                tempo = ''\n",
        "                for (u, m, k) in downlink1:\n",
        "                    if tempo == k: continue\n",
        "                    iternum = 1\n",
        "                    while True:\n",
        "                        try:\n",
        "                            rr = get(m)\n",
        "                            zz = rr.content.decode(\"utf-8\")\n",
        "                            if iternum > 1: print('\\n')\n",
        "                            break\n",
        "                        except KeyboardInterrupt: keyinter()\n",
        "                        except Exception: iternum = retrynow(iternum)\n",
        "                        iternum = iternum + 1\n",
        "                    try: downlink2 = findall('\"(https://[^\" \\t\\n\\r\\f\\v]*?ak[^\" \\t\\n\\r\\f\\v]+?/download/.+?)\"', zz)\n",
        "                    except: print('Error in the following link:', zz)\n",
        "                    if len(downlink2) > 1: downlink2 = [downlink2[0]]\n",
        "                    sizes.append(k)\n",
        "                    quals.append(u)\n",
        "                    for ii in downlink2: allLinks1.append(ii)\n",
        "                    tempo = k\n",
        "            print('\\n')\n",
        "            allLinks2 = []\n",
        "            avail_quals = unique(quals).tolist()\n",
        "            avail_quals.sort()\n",
        "            print('Available Qualities are: ', end='')\n",
        "            for i in avail_quals: print(quals_dict[i], end=' ')\n",
        "            quals_real = [quals_dict[i] for i in sorted(avail_quals)][::-1]\n",
        "            if len(avail_quals) != 1:\n",
        "                print('\\nChoose the desired quality (or press Enter for all qualities): ')\n",
        "                nummm = 1\n",
        "                numlist = []\n",
        "                quals_real_dic = {}\n",
        "                for i in quals_real:\n",
        "                    print('Press [' + str(nummm) + '] for', i + 'p')\n",
        "                    numlist = numlist + [str(nummm)]\n",
        "                    quals_real_dic[str(nummm)] = i\n",
        "                    nummm = nummm + 1\n",
        "                    if i == quals_real[-1]: print('')\n",
        "                Qual = input()\n",
        "                while True:\n",
        "                    if Qual in numlist or Qual == '': break\n",
        "                    #elif Qual.encode() == b'\\x03': keyinter()\n",
        "                    else: \n",
        "                        print('Invalid input! Choose the desired quality (or press Enter for all qualities): ')\n",
        "                        Qual = input()\n",
        "                if Qual in quals_dict: Qual = quals_real_dic[Qual]\n",
        "            else:\n",
        "                Qual = quals_dict[avail_quals[0]]\n",
        "            if Qual == '': print('All available qualities are added!')\n",
        "            else: print('\\n' + Qual + 'p is chosen')\n",
        "            print('')\n",
        "            chosensizes = []\n",
        "            savedsizes = sizes\n",
        "            #for URL,size, qual in zip(allLinks1, sizes, quals):\n",
        "                #if Qual == '': pass\n",
        "                #elif qual != quals_dict_rev[Qual]: continue\n",
        "                #chosensizes = chosensizes + [size]\n",
        "                #iternum = 1\n",
        "                #while True:\n",
        "                #    try:\n",
        "                #        r = get(URL)\n",
        "                #        s = r.content.decode(\"utf-8\")\n",
        "                #        if iternum > 1: print('\\n')\n",
        "                #        break\n",
        "                #    except KeyboardInterrupt: keyinter()\n",
        "                #    except Exception: iternum = retrynow(iternum)\n",
        "                #    iternum = iternum + 1\n",
        "                #final = findall('<a href=\"(https://.+?/download.+?)\"', s)[0]\n",
        "                #allLinks2.append(final)\n",
        "                #kkk = \"Saving download links... ( \" + str(round(100* (allLinks1.index(URL)+1)/len(allLinks1))) + ' %' + \" )\"\n",
        "                #stdout.flush()\n",
        "                #stdout.write('\\r'+ kkk)\n",
        "            for i in allLinks1: print(i)",
        "            kkk = \"Saving download links... ( 100 % )\"\n",
        "            stdout.flush()\n",
        "            stdout.write('\\r'+ kkk)\n",
        "            print('\\n')\n",
        "            sizesorted1 = [str(i) + '   ' + ii + '\\n' for i, ii in zip(allLinks2, chosensizes) if i.lower().find('1080p') != -1]\n",
        "\n",
        "            sizesorted2 = ['\\n\\n'] + [str(k) + '   ' + kk + '\\n' for k, kk in zip(allLinks2, chosensizes) if k.lower().find('720p') != -1]\n",
        "            if len(sizesorted1) == 0: sizesorted2.remove(sizesorted2[0])\n",
        "\n",
        "            sizesorted3 = ['\\n\\n'] + [str(j) + '   ' + jj + '\\n' for j, jj in zip(allLinks2, chosensizes) if j.lower().find('480p') != -1]\n",
        "            if len(sizesorted2) == 1: sizesorted3.remove(sizesorted3[0])\n",
        "\n",
        "            sizesorted4 = ['\\n\\n'] + [str(m) + '   ' + mm + '\\n' for m, mm in zip(allLinks2, chosensizes) if m.lower().find('360p') != -1]\n",
        "            if len(sizesorted3) == 1: sizesorted4.remove(sizesorted4[0])\n",
        "\n",
        "            sizesorted5 = ['\\n\\n'] + [str(m) + '   ' + mm + '\\n' for m, mm in zip(allLinks2, chosensizes) if m.lower().find('360p') == -1 and m.lower().find('480p') == -1 and m.lower().find('720p') == -1 and m.lower().find('1080p') == -1]\n",
        "            if len(sizesorted4) == 1: sizesorted5.remove(sizesorted5[0])\n",
        "\n",
        "            sizesorted = sizesorted1 + sizesorted2 + sizesorted3 + sizesorted4 + sizesorted5\n",
        "            directory = name + '.txt'\n",
        "        if len(links) != 0:\n",
        "            pathx = '/content' + '/Akwam-links'\n",
        "            if not isdir(pathx):\n",
        "                mkdir(pathx)\n",
        "            directory = pathx + '/' + directory\n",
        "            c = 1\n",
        "            print(\"Download links saved to -->> \", directory)\n",
        "            text = ' '.join(chosensizes)\n",
        "            try: gigas = sum([float(dig.replace(',', '')) for dig in findall(\"([0-9.,]+) GB\", text)])\n",
        "            except ValueError: gigas = 0.0\n",
        "            try: megas = sum([float(dig.replace(',', '')) for dig in findall(\"([0-9.,]+) MB\", text)])\n",
        "            except ValueError: megas = 0.0\n",
        "            total = gigas + megas / 1024\n",
        "            print(\"\\nTotal size is\", round(total, 3), 'GB')\n",
        "            if isfile(directory):\n",
        "                txts = '\\nFile ' + directory.split('/')[-1] +' already Exists, do you want to overwrite [y] or rename [n]? Press [y] to overwrite or [n] to rename: '\n",
        "                print(txts)\n",
        "                ends = input()\n",
        "                if ends != 'y':\n",
        "                    print(\"Renamed\")\n",
        "                    while isfile(directory):\n",
        "                        rep = findall('[0-9]*[.]txt', directory)[0]\n",
        "                        directory = directory.replace(rep, str(c) + '.txt')\n",
        "                        c = c + 1\n",
        "                else:\n",
        "                    print(\"Overwritten\")\n",
        "            with open(directory, 'wb') as fhand:\n",
        "                tots = '\"\"\" Total Size is ' + str(round(total, 3)) + ' GB \"\"\"'\n",
        "                tExt = tots.center(len(max(sizesorted, key=len))) + '\\n\\n'\n",
        "                fhand.write(tExt.encode(\"utf-8\"))\n",
        "                for i in range(0, len(sizesorted)):\n",
        "                    row = sizesorted[i]\n",
        "                    fhand.write(row.encode(\"utf8\"))\n",
        "                texT = '\\n\\n\\n' + '\"\"\"Download Links with no sizes (for jdownloader batch download)\"\"\"'.center(len(max(sizesorted, key=len).split('   ')[0])) + '\\n\\n\\n'\n",
        "                fhand.write(texT.encode(\"utf8\"))\n",
        "                copyall = ''\n",
        "                for i in range(0, len(sizesorted)):\n",
        "                    copyall = copyall + row\n",
        "                    row = sizesorted[i].split('   ')[0]+'\\n'\n",
        "                    fhand.write(row.encode(\"utf8\"))\n",
        "                print(copyall)\n",
        "                break\n",
        "except KeyboardInterrupt: \n",
        "    print(\"\\n\\nPROGRAM INTERRUPT BY USER\\n\")\n",
        "    raise SystemExit\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        }
      ]
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "akwam-dl_forColab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1lIpge/Oohx3af8B7smhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EyadNasr/akwam-dl/blob/main/akwam_dl_forColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "OYQZzgpUmzyl",
        "outputId": "2cc6ba39-94a6-443f-b6fa-e0e9f308bf38"
      },
      "source": [
        "\n",
        "#@markdown <br><center><img src='https://raw.githubusercontent.com/EyadNasr/akwam-dl/main/akwam_logo.ico' height=\"50\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h3>Akwam Links Generator</h3></center><br>\n",
        "\n",
        "import os\n",
        "if not os.path.isdir('/content/akwam-dl'):\n",
        "  !git clone https://github.com/EyadNasr/akwam-dl\n",
        "  os.chdir('/content/akwam-dl')\n",
        "\n",
        "\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from sys import stdout, stdin\n",
        "from re import match, findall, DOTALL\n",
        "from requests import get\n",
        "from numpy import unique\n",
        "from os import mkdir,chdir, getcwd, system\n",
        "from os.path import isfile, isdir\n",
        "from time import sleep\n",
        "from Arabic_Reshaper import reshape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def connproblem():\n",
        "    print(\"\\n\\nTHERE IS A PROBLEM WITH YOUR CONNECTION, CHECK YOUR INTERNET CONNENCTION AND TRY AGAIN!\")\n",
        "    ask = input('\\nTry again [y] or quit [n]? Press [y] to retry or [n] to quit')\n",
        "    if ask == 'y' or ask == 'Y': \n",
        "        print('')\n",
        "        pass\n",
        "    else: raise SystemExit\n",
        "\n",
        "\n",
        "def retrynow(num):\n",
        "    ssss = 'CONNECTION ERROR... Retrying... (' + str(num) + ')'\n",
        "    if num == 1: print('\\n')\n",
        "    stdout.flush()\n",
        "    stdout.write('\\r'+ ssss)\n",
        "    sleep(10)\n",
        "    if num%10 == 0: connproblem()\n",
        "    return num\n",
        "\n",
        "\n",
        "def keyinter():\n",
        "    print(\"\\n\\nPROGRAM INTERRUPT BY USER\\n\")\n",
        "    raise SystemExit\n",
        "\n",
        "\n",
        "def getlinks(url, stwith):\n",
        "    iternum = 1\n",
        "    while True:\n",
        "        try:\n",
        "            hdr = {'User-Agent': 'Mozilla/5.0'}\n",
        "            req = Request(url,headers=hdr)\n",
        "            page = urlopen(req).read()\n",
        "            if iternum > 1: print('\\n')\n",
        "            break\n",
        "        except KeyboardInterrupt: keyinter()\n",
        "        except Exception: iternum = retrynow(iternum)\n",
        "        iternum = iternum + 1\n",
        "    soup = BeautifulSoup(page, \"html.parser\")\n",
        "# Retrieve all of the anchor tags\n",
        "    tags = soup('a')\n",
        "    #lst = [tag.get('href', '') for tag in tags if match(stwith, tag.get('href', ''))]\n",
        "    lst = []\n",
        "    epidic = {}\n",
        "    for tag in tags:\n",
        "        if match(stwith, tag.get('href', '')) and tag.get('class') == ['text-white']:\n",
        "            lst = lst + [tag.get('href', '')]\n",
        "            #print(tag.contents)\n",
        "            epidic[int(findall('.+? ([0-9]+)', tag.contents[0])[0])] = tag.get('href', '')\n",
        "    #print(epidic)\n",
        "    #newlst = [item for item in lst if lst.count(item) == 2]\n",
        "    #newlst = newlst[::-2]\n",
        "    return(epidic)\n",
        "\n",
        "\n",
        "def getlistOfSeasons(parent, findit, fff, episodesFlag):\n",
        "    if findit == '\"(https://.*?akwam.+?/(movie|series)/.+?)\"':\n",
        "        findit1 = '\"(https://.*?akwam.+?/series/.+?)\"'\n",
        "        findit2 = '\"(https://.*?akwam.+?/movie/.+?)\"'\n",
        "        finditboth = [findit1, findit2]\n",
        "        parentboth = [parent+'series', parent+'movie']\n",
        "    else:\n",
        "        finditboth = [findit]\n",
        "        parentboth = [parent]\n",
        "    bothdict = {}\n",
        "    extracted_websub = ''\n",
        "    for both1, both2 in zip(parentboth, finditboth):\n",
        "        parent = both1\n",
        "        iternum = 1\n",
        "        while True:\n",
        "            try:\n",
        "                r = get(parent)\n",
        "                x = r.content.decode(\"utf-8\")\n",
        "                findit = both2\n",
        "                r = get(parent)\n",
        "                x = r.content.decode(\"utf-8\")\n",
        "                if iternum > 1: print('\\n')\n",
        "                break\n",
        "            except KeyboardInterrupt: keyinter()\n",
        "            except Exception: iternum = retrynow(iternum)\n",
        "            iternum = iternum + 1\n",
        "        if fff:\n",
        "            morePages = findall('page=([1-9]+)', x)\n",
        "            Pages = unique(morePages).tolist()\n",
        "            Pages = [1] + [int(i) for i in Pages]\n",
        "            Pages = list(range(1, max(Pages)+1))\n",
        "            all_X = ''\n",
        "            for i in Pages:\n",
        "                if i == 1: all_X = all_X + ' ' + x\n",
        "                else:\n",
        "                    parent_i = parent + '&page=' + str(i)\n",
        "                    iternum = 1\n",
        "                    while True:\n",
        "                        try:\n",
        "                            r = get(parent_i)\n",
        "                            x = r.content.decode(\"utf-8\")\n",
        "                            if iternum > 1: print('\\n')\n",
        "                            break\n",
        "                        except KeyboardInterrupt: keyinter()\n",
        "                        except Exception: iternum = retrynow(iternum)\n",
        "                        iternum = iternum + 1\n",
        "                    all_X = all_X + ' ' + x\n",
        "            aka = r'<h3 class=\"entry-title font-size-14 m-0\"><a href=\"(https://.*?akwam.+?/(movie|series)/[^\" \\t\\n\\r\\f\\v]+)\".+\\n.+\\n.+\"badge badge-pill badge-secondary ml-1\">([0-9][0-9][0-9][0-9])</span>'\n",
        "            uniq = findall(aka, all_X)\n",
        "            try: \n",
        "                if len(uniq) > 0: \n",
        "                    extracted_websub = findall('(https://.+?)/[^ \\t\\n\\r\\f\\v]+', uniq[0][0])[0]\n",
        "                    #uniq.remove(parent)\n",
        "            except: \n",
        "                pass\n",
        "            unsrt = [int(i[0].split('/')[-2]) for i in uniq]\n",
        "            dicto = {}\n",
        "            \n",
        "            for i in range(0, len(uniq)): dicto[unsrt[i]] = uniq[i][0] + ' ' + uniq[i][2]\n",
        "        else:\n",
        "            uniq = findall(findit, x)\n",
        "            extracted_websub = findall('(https://.*?akwam.+?)/[^ \\t\\n\\r\\f\\v]+', uniq[0])[0]\n",
        "            uniq = unique(uniq).tolist()\n",
        "            unsrt = [int(i.split('/')[-2]) for i in uniq]\n",
        "            dicto = {}\n",
        "            for i in range(0, len(uniq)): dicto[unsrt[i]] = uniq[i]\n",
        "        bothdict.update(dicto)\n",
        "    dicto = bothdict\n",
        "    lsts = []\n",
        "    if len(dicto) == 1: sstr = ' Link found'\n",
        "    else: sstr = ' Links found'\n",
        "    print('\\n' + str(len(dicto)) + sstr)\n",
        "    count = 1\n",
        "    for j in sorted(dicto):\n",
        "        #reshaped_text = reshape(dicto[j])\n",
        "        bidi_text = dicto[j]\n",
        "        s = str(dicto[j].encode())\n",
        "        links = []\n",
        "        TYPE = '\" [' + bidi_text.split('/')[-3] + ']'\n",
        "        ending = input('\\n' + str(count) + ' Do you want to download \"' + bidi_text.split('/')[-1].replace('-s-', \"'s \").replace('-', ' ') + TYPE + ' ?')\n",
        "        flag = True\n",
        "        if ending == 'y'  or ending == 'Y':\n",
        "            if bidi_text.find('series') != -1:\n",
        "                if fff: linksdic = getlinks(findall(\"'(.+)'\", s)[0][:-5], extracted_websub + '/episode/')\n",
        "                else: linksdic = getlinks(findall(\"'(.+)'\", s)[0], extracted_websub + '/episode/')\n",
        "                episodessorted = sorted(linksdic)\n",
        "                links = [linksdic[i] for i in episodessorted]\n",
        "                if episodesFlag:\n",
        "                    print('\\n' + '\"' + bidi_text.split('/')[-1].replace('-', ' ') + '\" has', max(episodessorted), 'episodes.')\n",
        "                    episodeslst = input('Enter the desired episodes: ')\n",
        "                    cond = 0\n",
        "                    numset = '0123456789:,'\n",
        "                    while cond == 0:\n",
        "                        episodeslst = episodeslst.replace(' ', '').replace('\\t', '').split(',')\n",
        "                        for e in episodeslst:\n",
        "                            #if all(x in numset for x in episodeslst): pass\n",
        "                            if len(findall('^[1-9]+[0]*$', e)) > 0 and int(e) <= max(episodessorted): pass\n",
        "                            elif len(findall('^[1-9]+[0]*:[1-9]+[0]*$', e)) > 0 and int(e.split(':')[0]) < int(e.split(':')[1]) and int(e.split(':')[1]) <=max(episodessorted): pass\n",
        "                            else:\n",
        "                                episodeslst = input('Invalid input, Enter the desired episodes: ')\n",
        "                                cond = cond + 1\n",
        "                        if cond > 0: cond = 0\n",
        "                        else: break\n",
        "                    \n",
        "                    candlist = []\n",
        "                    for i in episodeslst:\n",
        "                        if ':' not in i: candlist.append(int(i))\n",
        "                        else: candlist = candlist + list(range(int(i.split(':')[0]), int(i.split(':')[1])+1))\n",
        "                    pro = sorted(unique(candlist).tolist())\n",
        "                    links = []\n",
        "                    missing = []\n",
        "                    for i in pro:\n",
        "                        if i not in linksdic: missing = missing + [i]\n",
        "                        else: links = links + [linksdic[i]]\n",
        "                    if len(missing) > 0:\n",
        "                        print('\\nThe following episodes are missing from the website: ', end='')\n",
        "                        for q in missing: print(q, '', end='')\n",
        "                        print('')\n",
        "            elif bidi_text.find('movie') != -1:\n",
        "                if fff: links = [bidi_text[:-5]]\n",
        "                else: links = [bidi_text]\n",
        "        lsts = lsts + links\n",
        "        if ending == 'q':\n",
        "            break\n",
        "        count = count + 1\n",
        "    links = lsts\n",
        "    return links\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    websub = 'https://.*?akwam.+?'\n",
        "    flag = False\n",
        "    episodesFlag = False\n",
        "    while True:\n",
        "        allLinks1 = []\n",
        "        sizes = []\n",
        "        quals = []\n",
        "        quals_dict = {'5': '1080', '4': '720', '3': '480', '2': '360', '1': '240'}\n",
        "        quals_dict_rev = {'1080': '5', '720': '4', '480': '3', '360': '2', '240': '1'}\n",
        "        parent = input('Paste Movie or Series link, (or write what you want to search for): ')\n",
        "        name = parent.split('/')[-1].split('%')[0].replace('-', ' ').strip()\n",
        "        if parent.find('https:') == -1:\n",
        "            parent = 'https://akwam.cc/search?q=' + parent\n",
        "        if parent.find('series') != -1:\n",
        "            fff = False\n",
        "            print(\"\\nPress [q] to end questions, [y] to download or [n] to skip:\")\n",
        "            websub1 = 'https://' + parent[8:].split('/')[0]\n",
        "            links = getlistOfSeasons(parent, '\"(' + websub1 + '/series/.+?)\"', fff, episodesFlag)\n",
        "        elif parent.find('search') != -1:\n",
        "            fff = True\n",
        "            ending = input('\\nIs it a Movie or a Series or both?\\n(Enter [m] for Movie, [s] for Series , [e] for specific Episodes of a series or any other key for both Movies and Series)\\n')\n",
        "            if ending == 'm' or ending == 'M': \n",
        "                Type = '&section=movie'\n",
        "                Typo = '&section=movie'\n",
        "            elif ending == 's' or ending == 'S': \n",
        "                Type = '&section=series'\n",
        "                Typo = '&section=series'\n",
        "            elif ending == 'e' or ending == 'E':\n",
        "                Type = '&section=series'\n",
        "                Typo = '&section=series'\n",
        "                episodesFlag = True\n",
        "            else: \n",
        "                Type = '&section=(movie|series)'\n",
        "                Typo = '&section='\n",
        "            if episodesFlag: print('To specify episodes: type the range of episodes or episode numbers separated by commas\\nfor example: 1,4,7,9:12,15')\n",
        "            else: print('')\n",
        "            print(\"\\nPress [q] to end questions, [y] to download or [n] to skip:\")\n",
        "            links = getlistOfSeasons(parent.replace(' ', '+')+Typo, '\"(' + websub + '/' + Type[9:] + '/.+?)\"', fff, episodesFlag)\n",
        "            name = parent.split('/')[-1].split('%')[0].replace('-', ' ').split('&')[0].split('?q=')[1].replace('+', ' ')\n",
        "            if len(links) == 0 and not flag:\n",
        "                print('\\nDid not find what you were searching for!')\n",
        "        elif parent.find('movie') != -1:\n",
        "            links = [parent]\n",
        "        else: links = []\n",
        "        if len(links) == 0:\n",
        "            print('\\nZero links extracted!')\n",
        "        else:\n",
        "            print('')\n",
        "            for i in links:\n",
        "                sss = \"Gathering download pages... ( \" + str(links.index(i)+1) + \" out of \" + str(len(links)) + \" )\"\n",
        "                stdout.flush()\n",
        "                stdout.write('\\r'+ sss)\n",
        "                iternum = 1\n",
        "                while True:\n",
        "                    try:\n",
        "                        r = get(i)\n",
        "                        z = r.content.decode(\"utf-8\")\n",
        "                        if iternum > 1: print('\\n')\n",
        "                        break\n",
        "                    except KeyboardInterrupt: keyinter()\n",
        "                    except Exception: iternum = retrynow(iternum)\n",
        "                    iternum = iternum + 1\n",
        "                #downlink1 = findall('\"(http://go.akwam' + websuper + '/link/.+?)\".+?([0-9.,]+ [MG]B)', z)\n",
        "                #downlink1 = findall('data-quality=\"([1-5])\">.+?\"(http://re.two.re/link/.+?)\".+?([0-9.,]+ [MG]B)', z, DOTALL)\n",
        "                downlink1 = findall('data-quality=\"([1-5])\">.+?<a href=\"(http://[^\" \\t\\n\\r\\f\\v]+/link/[^\" \\t\\n\\r\\f\\v]+?)\".+?([0-9.,]+ [MG]B)</span>', z, DOTALL)\n",
        "                #downlink1 = findall('\"(' + websub + '/download/.+?)\".+?([0-9.,]+ [MG]B)', z)\n",
        "                tempo = ''\n",
        "                for (u, m, k) in downlink1:\n",
        "                    if tempo == k: continue\n",
        "                    iternum = 1\n",
        "                    while True:\n",
        "                        try:\n",
        "                            rr = get(m)\n",
        "                            zz = rr.content.decode(\"utf-8\")\n",
        "                            if iternum > 1: print('\\n')\n",
        "                            break\n",
        "                        except KeyboardInterrupt: keyinter()\n",
        "                        except Exception: iternum = retrynow(iternum)\n",
        "                        iternum = iternum + 1\n",
        "                    downlink2 = findall('\"(https://[^\" \\t\\n\\r\\f\\v]*?akwam[^\" \\t\\n\\r\\f\\v]+?/download/.+?)\"', zz)\n",
        "                    if len(downlink2) > 1: downlink2 = [downlink2[0]]\n",
        "                    sizes.append(k)\n",
        "                    quals.append(u)\n",
        "                    for ii in downlink2: allLinks1.append(ii)\n",
        "                    tempo = k\n",
        "            print('\\n')\n",
        "            allLinks2 = []\n",
        "            avail_quals = unique(quals).tolist()\n",
        "            avail_quals.sort()\n",
        "            print('Available Qualities are: ', end='')\n",
        "            for i in avail_quals: print(quals_dict[i], end=' ')\n",
        "            quals_real = [quals_dict[i] for i in sorted(avail_quals)][::-1]\n",
        "            if len(avail_quals) != 1:\n",
        "                print('\\nChoose the desired quality (or press Enter for all qualities): ')\n",
        "                nummm = 1\n",
        "                numlist = []\n",
        "                quals_real_dic = {}\n",
        "                for i in quals_real:\n",
        "                    print('Press [' + str(nummm) + '] for', i + 'p')\n",
        "                    numlist = numlist + [str(nummm)]\n",
        "                    quals_real_dic[str(nummm)] = i\n",
        "                    nummm = nummm + 1\n",
        "                    if i == quals_real[-1]: print('')\n",
        "                Qual = input()\n",
        "                while True:\n",
        "                    if Qual in numlist or Qual == '': break\n",
        "                    #elif Qual.encode() == b'\\x03': keyinter()\n",
        "                    else: \n",
        "                        print('Invalid input! Choose the desired quality (or press Enter for all qualities): ')\n",
        "                        Qual = input()\n",
        "                if Qual in quals_dict: Qual = quals_real_dic[Qual]\n",
        "            else:\n",
        "                Qual = quals_dict[avail_quals[0]]\n",
        "            if Qual == '': print('All available qualities are added!')\n",
        "            else: print('\\n' + Qual + 'p is chosen')\n",
        "            print('')\n",
        "            chosensizes = []\n",
        "            savedsizes = sizes\n",
        "            for URL,size, qual in zip(allLinks1, sizes, quals):\n",
        "                if Qual == '': pass\n",
        "                elif qual != quals_dict_rev[Qual]: continue\n",
        "                chosensizes = chosensizes + [size]\n",
        "                iternum = 1\n",
        "                while True:\n",
        "                    try:\n",
        "                        r = get(URL)\n",
        "                        s = r.content.decode(\"utf-8\")\n",
        "                        if iternum > 1: print('\\n')\n",
        "                        break\n",
        "                    except KeyboardInterrupt: keyinter()\n",
        "                    except Exception: iternum = retrynow(iternum)\n",
        "                    iternum = iternum + 1\n",
        "                final = findall('<a href=\"(https://s.+?[.]/download.+?)\"', s)[0]\n",
        "                allLinks2.append(final)\n",
        "                kkk = \"Saving download links... ( \" + str(round(100* (allLinks1.index(URL)+1)/len(allLinks1))) + ' %' + \" )\"\n",
        "                stdout.flush()\n",
        "                stdout.write('\\r'+ kkk)\n",
        "            kkk = \"Saving download links... ( 100 % )\"\n",
        "            stdout.flush()\n",
        "            stdout.write('\\r'+ kkk)\n",
        "            print('\\n')\n",
        "            sizesorted1 = [str(i) + '   ' + ii + '\\n' for i, ii in zip(allLinks2, chosensizes) if i.lower().find('1080p') != -1]\n",
        "\n",
        "            sizesorted2 = ['\\n\\n'] + [str(k) + '   ' + kk + '\\n' for k, kk in zip(allLinks2, chosensizes) if k.lower().find('720p') != -1]\n",
        "            if len(sizesorted1) == 0: sizesorted2.remove(sizesorted2[0])\n",
        "\n",
        "            sizesorted3 = ['\\n\\n'] + [str(j) + '   ' + jj + '\\n' for j, jj in zip(allLinks2, chosensizes) if j.lower().find('480p') != -1]\n",
        "            if len(sizesorted2) == 1: sizesorted3.remove(sizesorted3[0])\n",
        "\n",
        "            sizesorted4 = ['\\n\\n'] + [str(m) + '   ' + mm + '\\n' for m, mm in zip(allLinks2, chosensizes) if m.lower().find('360p') != -1]\n",
        "            if len(sizesorted3) == 1: sizesorted4.remove(sizesorted4[0])\n",
        "\n",
        "            sizesorted5 = ['\\n\\n'] + [str(m) + '   ' + mm + '\\n' for m, mm in zip(allLinks2, chosensizes) if m.lower().find('360p') == -1 and m.lower().find('480p') == -1 and m.lower().find('720p') == -1 and m.lower().find('1080p') == -1]\n",
        "            if len(sizesorted4) == 1: sizesorted5.remove(sizesorted5[0])\n",
        "\n",
        "            sizesorted = sizesorted1 + sizesorted2 + sizesorted3 + sizesorted4 + sizesorted5\n",
        "            directory = name + '.txt'\n",
        "        if len(links) != 0:\n",
        "            pathx = '/content' + '/Akwam-links'\n",
        "            if not isdir(pathx):\n",
        "                mkdir(pathx)\n",
        "            directory = pathx + '/' + directory\n",
        "            c = 1\n",
        "            print(\"Download links saved to -->> \", directory)\n",
        "            text = ' '.join(chosensizes)\n",
        "            try: gigas = sum([float(dig.replace(',', '')) for dig in findall(\"([0-9.,]+) GB\", text)])\n",
        "            except ValueError: gigas = 0.0\n",
        "            try: megas = sum([float(dig.replace(',', '')) for dig in findall(\"([0-9.,]+) MB\", text)])\n",
        "            except ValueError: megas = 0.0\n",
        "            total = gigas + megas / 1024\n",
        "            print(\"\\nTotal size is\", round(total, 3), 'GB')\n",
        "            if isfile(directory):\n",
        "                txts = '\\nFile ' + directory.split('/')[-1] +' already Exists, do you want to overwrite [y] or rename [n]? Press [y] to overwrite or [n] to rename: '\n",
        "                print(txts)\n",
        "                ends = input()\n",
        "                if ends != 'y':\n",
        "                    print(\"Renamed\")\n",
        "                    while isfile(directory):\n",
        "                        rep = findall('[0-9]*[.]txt', directory)[0]\n",
        "                        directory = directory.replace(rep, str(c) + '.txt')\n",
        "                        c = c + 1\n",
        "                else:\n",
        "                    print(\"Overwritten\")\n",
        "            with open(directory, 'wb') as fhand:\n",
        "                tots = '\"\"\" Total Size is ' + str(round(total, 3)) + ' GB \"\"\"'\n",
        "                tExt = tots.center(len(max(sizesorted, key=len))) + '\\n\\n'\n",
        "                fhand.write(tExt.encode(\"utf-8\"))\n",
        "                for i in range(0, len(sizesorted)):\n",
        "                    row = sizesorted[i]\n",
        "                    fhand.write(row.encode(\"utf8\"))\n",
        "                texT = '\\n\\n\\n' + '\"\"\"Download Links with no sizes (for jdownloader batch download)\"\"\"'.center(len(max(sizesorted, key=len).split('   ')[0])) + '\\n\\n\\n'\n",
        "                fhand.write(texT.encode(\"utf8\"))\n",
        "                copyall = ''\n",
        "                for i in range(0, len(sizesorted)):\n",
        "                    copyall = copyall + row\n",
        "                    row = sizesorted[i].split('   ')[0]+'\\n'\n",
        "                    fhand.write(row.encode(\"utf8\"))\n",
        "                print(copyall)\n",
        "                break\n",
        "except KeyboardInterrupt: \n",
        "    print(\"\\n\\nPROGRAM INTERRUPT BY USER\\n\")\n",
        "    raise SystemExit\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        }
      ]
    }
  ]
}
